{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f54f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "import pymc\n",
    "import xarray as xr\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6a5fac",
   "metadata": {},
   "source": [
    "# A small Bayesian Analysis\n",
    "\n",
    "The [Michaelis-Menten kinetics](https://en.wikipedia.org/wiki/Michaelis%E2%80%93Menten_kinetics) is the simplest model of a enzyme-catalyzed reaction. It maps the substrate concentration $c$ to the reaction rate $v$ by\n",
    "$$ v(c) = v_\\text{max} \\cdot \\frac{c}{K_m + c}$$\n",
    "$v_\\text{max}$ and $K_m$ are enzyme-specific parameters, both constrained to $(0, \\infty)$. We will use the Michaelis-Menten model to infer these parameters from generated reaction rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f435da78",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Execute the cell below to generate the data for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38aadf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def michaelis_menten(v_max, k_m, c):\n",
    "    return v_max * c / (k_m + c)\n",
    "\n",
    "v_max = 1.\n",
    "k_m = 0.1\n",
    "\n",
    "n = 10\n",
    "sigma = 1e-1\n",
    "c = np.power(10, np.linspace(-3, 1, num=n))\n",
    "v = michaelis_menten(v_max, k_m, c) + np.random.normal(loc=0, scale=sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093f614f",
   "metadata": {},
   "source": [
    "### Explore the data\n",
    "\n",
    "- Plot substrate data `c` against the \"measured\" reaction rates `v`. Explain what is going on in terms of substrate concentration and enzyme activity.\n",
    "- Try using different values for `v_max` and `k_m`. Explain how they effect the generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcb1db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ce8cc4e",
   "metadata": {},
   "source": [
    "### Select appropriate priors\n",
    "\n",
    "Experiment to find suitable priors. Remember, that both parameters have lower bounds which needs to be reflected in the choice of prior. Execute the prior predictive check below. Because you don't have any particular knowledge, avoid too informative priors. You can assume, however, that you are sure about magnitude of the measurement values.\n",
    "\n",
    "You will now start to use `pymc`, a software for Bayesian Inference, and MCMC. In `pymc`, model variables are specified by their prior, e.g. \n",
    "`var_name = pymc.Normal(\"variable name\", 0, 1)`.\n",
    "\n",
    "Some inspiration:\n",
    "- [Half normal](https://www.pymc.io/projects/docs/en/latest/api/distributions/generated/pymc.HalfNormal.html) (prefers close to zero values) or [Log normal](https://www.pymc.io/projects/docs/en/latest/api/distributions/generated/pymc.LogNormal.html) distributions (probablity mass peak can be shifted)\n",
    "- [Bound transformation](https://www.pymc.io/projects/docs/en/latest/api/distributions/generated/pymc.distributions.transforms.Interval.html#pymc.distributions.transforms.Interval) for any [continuous distribution](https://www.pymc.io/projects/docs/en/latest/api/distributions/continuous.html)\n",
    "- [Half flat](https://www.pymc.io/projects/docs/en/latest/api/distributions/generated/pymc.HalfFlat.html) distribution (least informative choice, but is improper and you can't do prior predictive checks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d310fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pymc.Model() as model:\n",
    "    # Priors\n",
    "    v_max_rv = ... # e.g.: pymc.Uniform(\"v_max\", 0, 1)\n",
    "    k_m_rv = ...\n",
    "    \n",
    "    # Likelihood\n",
    "    v_rv = michaelis_menten(v_max_rv, k_m_rv, c)\n",
    "    pymc.Normal(\"obs\", mu=v_rv, sigma=sigma, observed=v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fe17cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    trace = pymc.sample_prior_predictive(samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6311c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_pred = xr.DataArray(np.linspace(1e-3, 10, num=1000))\n",
    "v_pred = michaelis_menten(trace.prior[\"v_max\"], \n",
    "                          trace.prior[\"k_m\"],\n",
    "                          c_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1bd3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(c_pred, v_pred.stack(sample=(\"chain\", \"draw\")), color=\"tab:blue\", alpha=0.6)\n",
    "plt.xlabel(\"c\")\n",
    "plt.ylabel(\"v\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5d47bd",
   "metadata": {},
   "source": [
    "### Obtaining the posterior: MCMC sampling\n",
    "\n",
    "The next step is infering the posterior by MCMC. This can be easily done by `pymc` with the `pymc.sample` command. Look at the posterior plot. Are the results sensible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1153461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    trace = pymc.sample(500, chains=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b335eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pymc.plot_posterior(trace)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b50b43c",
   "metadata": {},
   "source": [
    "### Posterior Predictive Checks\n",
    "\n",
    "Posterior predictive checks can also be done easily by `pymc`. Run the code below code. Would you accept the results of the analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865fb9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    pymc.sample_posterior_predictive(trace, extend_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc71a581",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_pred = xr.DataArray(np.linspace(1e-3, 10, num=1000))\n",
    "v_pred = michaelis_menten(trace.posterior[\"v_max\"], \n",
    "                          trace.posterior[\"k_m\"],\n",
    "                          c_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e2e835",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(c_pred, v_pred.mean((\"chain\", \"draw\")), label=\"Mean outcome\", color=\"C1\", alpha=0.6)\n",
    "az.plot_hdi(c, trace.posterior_predictive[\"obs\"])\n",
    "plt.scatter(c, trace.observed_data[\"obs\"])\n",
    "plt.xlabel(\"c\")\n",
    "plt.ylabel(\"v\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
