{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35b7015-d27b-4bf2-bb6a-01daf26e682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "import pymc\n",
    "import xarray as xr\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eb891b",
   "metadata": {},
   "source": [
    "# 1. Bayesian Coin Toss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fdb9c9-d60b-49d8-8df5-b572282d64aa",
   "metadata": {},
   "source": [
    "### Setup \n",
    "Let's generate 500 coin tosses from a [Bernoulli distribution](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bernoulli.html?highlight=bernoulli#scipy.stats.bernoulli):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37411bc-a26a-4355-b7c8-b6e837552a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.5\n",
    "n_draws = 1000\n",
    "data = stats.bernoulli.rvs(p, size=n_draws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2b6889-c80b-48ad-8919-e1c682714754",
   "metadata": {},
   "source": [
    "### Explore the data\n",
    "Explore the data by calculating its [empirical mean](https://numpy.org/doc/stable/reference/generated/numpy.mean.html) and its [empirical  variance](https://numpy.org/doc/stable/reference/generated/numpy.var.html). Look up, how mean and variance of a [Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution) are defined. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a2680b-5022-48ca-9e0a-3c4602574f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43b73f7-563a-4ee4-ab2e-d8e5bd7871d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a277deb-9b6a-41ed-8371-062c3b82cb8c",
   "metadata": {},
   "source": [
    "### Code a plot function\n",
    "Fill out the function `plot_coin_toss` that computes the *posterior distribution* given a number of coin tosses as *data*. By choosing a suitable prior and doing some fancy math, we know that the posterior in this case is a *beta distribution* with $a = 1 + n_\\text{heads}, \\, b = 1 + n_\\text{trials} - n_\\text{heads}$.\n",
    "\n",
    "- Take the first $n_\\text{trials}$ draws from data and compute the number of heads.\n",
    "\n",
    "- Use the PDF (probability density function) of the [beta distribution](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.beta.html#scipy.stats.beta), to compute the posterior distribution for every point in `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b4712-9c16-441e-b3e8-f5ed9a404091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coin_toss(n_trials, data):\n",
    "    n_heads = ...\n",
    "\n",
    "    x = np.linspace(0, 1, 1000)\n",
    "    posterior_pdf = ...\n",
    "    \n",
    "    plt.title(\"%s trials, %s heads\" % (n_trials, n_heads))\n",
    "    plt.xlabel(\"$P(H)$, Probability of Heads\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.plot(x, posterior_pdf, label=\"observe %d tosses,\\n %d heads\" % (n_trials, n_heads))\n",
    "    plt.fill_between(x, 0, posterior_pdf, color=\"#aaaadd\", alpha=0.5)\n",
    "    plt.xlim((0., 1.))\n",
    "    plt.ylim((0., 30.))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219d6c24-6970-4cda-b5fd-e71dd13411d4",
   "metadata": {},
   "source": [
    "### Run multiple trials\n",
    "Execute the coin toss function for multiple number of trials (e.g. 0, 2, 10, 20, 50, 500). Is the result sensible? Describe what you see and what this means for the estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60504ce5-f01f-4065-9f31-9475394f6896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaeb07cd-82b6-47ce-9c60-06476d02be9a",
   "metadata": {},
   "source": [
    "### (Optional) Animate coin toss\n",
    "Use [Jupyter Widgets](https://ipywidgets.readthedocs.io/en/latest/) to build an jupyter notebook application with two sliders that modify $p$ and $n_\\text{trials}$. Set $n_\\text{draws}$ to a higher value. Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e11e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30f7cc0f",
   "metadata": {},
   "source": [
    "# 2. Michaelis Menten: A small Bayesian Analysis\n",
    "\n",
    "The [Michaelis-Menten kinetics](https://en.wikipedia.org/wiki/Michaelis%E2%80%93Menten_kinetics) is the simplest model of a enzyme-catalyzed reaction. It maps the substrate concentration $c$ to the reaction rate $v$ by\n",
    "$$ v(c) = v_\\text{max} \\cdot \\frac{c}{K_m + c}$$\n",
    "$v_\\text{max}$ and $K_m$ are enzyme-specific parameters, both constrained to $(0, \\infty)$. We will use the Michaelis-Menten model to infer these parameters from generated reaction rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0e4f06",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Execute the cell below to generate the data for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382bafbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def michaelis_menten(v_max, k_m, c):\n",
    "    return v_max * c / (k_m + c)\n",
    "\n",
    "v_max = 1.\n",
    "k_m = 0.1\n",
    "\n",
    "n = 10\n",
    "sigma = 1e-1\n",
    "c = np.power(10, np.linspace(-3, 1, num=n))\n",
    "v = michaelis_menten(v_max, k_m, c) + np.random.normal(loc=0, scale=sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788c53a7",
   "metadata": {},
   "source": [
    "### Explore the data\n",
    "\n",
    "- Plot substrate data `c` against the \"measured\" reaction rates `v`. Explain what is going on in terms of substrate concentration and enzyme activity.\n",
    "- Try using different values for `v_max` and `k_m`. Explain how they effect the generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a31caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "698e5ae7",
   "metadata": {},
   "source": [
    "### Select appropriate priors\n",
    "\n",
    "Experiment to find suitable priors. Remember, that both parameters have lower bounds which needs to be reflected in the choice of prior. Execute the prior predictive check below. Because you don't have any particular knowledge, avoid too informative priors. You can assume, however, that you are sure about magnitude of the measurement values.\n",
    "\n",
    "You will now start to use `pymc`, a software for Bayesian Inference, and MCMC. In `pymc`, model variables are specified by their prior, e.g. \n",
    "`var_name = pymc.Normal(\"variable name\", 0, 1)`.\n",
    "\n",
    "Some inspiration:\n",
    "- [Half normal](https://www.pymc.io/projects/docs/en/latest/api/distributions/generated/pymc.HalfNormal.html) (prefers close to zero values) or [Log normal](https://www.pymc.io/projects/docs/en/latest/api/distributions/generated/pymc.LogNormal.html) distributions (probablity mass peak can be shifted)\n",
    "- [Bound transformation](https://www.pymc.io/projects/docs/en/latest/api/distributions/generated/pymc.distributions.transforms.Interval.html#pymc.distributions.transforms.Interval) for any [continuous distribution](https://www.pymc.io/projects/docs/en/latest/api/distributions/continuous.html)\n",
    "- [Half flat](https://www.pymc.io/projects/docs/en/latest/api/distributions/generated/pymc.HalfFlat.html) distribution (least informative choice, but is improper and you can't do prior predictive checks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ed1a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pymc.Model() as model:\n",
    "    # Priors\n",
    "    v_max_rv = ... # e.g.: pymc.Uniform(\"v_max\", 0, 1)\n",
    "    k_m_rv = ...\n",
    "    \n",
    "    # Likelihood\n",
    "    v_rv = michaelis_menten(v_max_rv, k_m_rv, c)\n",
    "    pymc.Normal(\"obs\", mu=v_rv, sigma=sigma, observed=v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb60dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    trace = pymc.sample_prior_predictive(samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844a5bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_pred = xr.DataArray(np.linspace(1e-3, 10, num=1000))\n",
    "v_pred = michaelis_menten(trace.prior[\"v_max\"], \n",
    "                          trace.prior[\"k_m\"],\n",
    "                          c_pred)\n",
    "\n",
    "plt.plot(c_pred, v_pred.stack(sample=(\"chain\", \"draw\")), color=\"tab:blue\", alpha=0.6)\n",
    "plt.xlabel(\"c\")\n",
    "plt.ylabel(\"v\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19d12f3",
   "metadata": {},
   "source": [
    "### Obtaining the posterior: MCMC sampling\n",
    "\n",
    "The next step is infering the posterior by MCMC. This can be easily done by `pymc` with the `pymc.sample` command. Look at the posterior plot. Are the results sensible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de18684",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    trace = pymc.sample(500, chains=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6634d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pymc.plot_posterior(trace)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff29f5ba",
   "metadata": {},
   "source": [
    "### Posterior Predictive Checks\n",
    "\n",
    "Posterior predictive checks can also be done easily by `pymc`. Run the code below code. Would you accept the results of the analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ccf744",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    pymc.sample_posterior_predictive(trace, extend_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2398d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_pred = xr.DataArray(np.linspace(1e-3, 10, num=1000))\n",
    "v_pred = michaelis_menten(trace.posterior[\"v_max\"], \n",
    "                          trace.posterior[\"k_m\"],\n",
    "                          c_pred)\n",
    "\n",
    "plt.plot(c_pred, v_pred.mean((\"chain\", \"draw\")), label=\"Mean outcome\", color=\"C1\", alpha=0.6)\n",
    "az.plot_hdi(c, trace.posterior_predictive[\"obs\"])\n",
    "plt.scatter(c, trace.observed_data[\"obs\"])\n",
    "plt.xlabel(\"c\")\n",
    "plt.ylabel(\"v\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
